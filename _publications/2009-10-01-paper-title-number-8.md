---
title: "Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality"
collection: publications
category: conferences
permalink: /publication/assistvr-occluded-multi-selection
excerpt: 'We explore the possibility of leveraging large language models to assist multi-object selection tasks in virtual reality via a multimodal speech and raycast interaction technique, AssistVR. AssistVR outperforms the baseline technique when there are multiple target objects, even when the target objects were difficult to reference verbally.'
date: 2024-10-28
venue: '(Under Review)'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://arxiv.org/abs/2410.21091'
citation: 'Chen, J., Grubert, J., & Kristensson, P. O. (2024). Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality. arXiv preprint arXiv:2410.21091.'
---

Selection of occluded objects is a challenging problem in virtual reality, even more so if multiple objects are involved. With the advent of new artificial intelligence technologies, we explore the possibility of leveraging large language models to assist multi-object selection tasks in virtual reality via a multimodal speech and raycast interaction technique. We validate the findings in a comparative user study (n=24), where participants selected target objects in a virtual reality scene with different levels of scene perplexity. The performance metrics and user experience metrics are compared against a mini-map based occluded object selection technique that serves as the baseline. Results indicate that the introduced technique, AssistVR, outperforms the baseline technique when there are multiple target objects. Contrary to the common belief for speech interfaces, AssistVR was able to outperform the baseline even when the target objects were difficult to reference verbally. This work demonstrates the viability and interaction potential of an intelligent multimodal interactive system powered by large laguage models. Based on the results, we discuss the implications for design of future intelligent multimodal interactive systems in immersive environments.